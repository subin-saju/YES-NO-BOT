{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FS2Tqul72Km"
      },
      "source": [
        "___\n",
        "\n",
        "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
        "___\n",
        "# Question and Answer Chat Bots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu2qLuLo72Kp"
      },
      "source": [
        "----\n",
        "\n",
        "------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "collapsed": true,
        "id": "u3aPXMAB72Kr"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU_HkGubGd4u",
        "outputId": "57eb69f6-c70c-469c-93f4-b641ec8facf2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "collapsed": true,
        "id": "m0BXt2wh72Ks"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/train_qa.txt', \"rb\") as fp:   # Unpickling\n",
        "    train_data =  pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "id": "fJaDPxbD72Ks"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/test_qa.txt', \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYG7Ij7G72Kt"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bGul6x_72Kt"
      },
      "source": [
        "## Exploring the Format of the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC25t33-72Kt",
        "outputId": "d62efa2d-231b-40b7-9748-113a95151768"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "type(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFevdR8272Kv",
        "outputId": "ae87693f-ccd1-499c-d2bd-6c3803191ef4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "type(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7F2GrzO72Kv",
        "outputId": "320234e5-e253-44fe-b495-eee9a4c2adc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaIfqFmj72Kv",
        "outputId": "f8648ca5-edb3-4539-a170-e36fcb6023d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGV8fapp72Kw",
        "outputId": "7bcf6ef7-39a4-4992-9236-059ef14513da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "v7ppVCun72Kw",
        "outputId": "b0b2f1aa-64fe-48d2-c48a-df081ab76eff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "' '.join(train_data[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k1PVrkoW72Kw",
        "outputId": "8c8b7661-4cb7-4333-881b-f2349461fb22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Is Sandra in the hallway ?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "' '.join(train_data[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wjmOH-wc72Kx",
        "outputId": "ca006d9b-a688-4cbd-cb3c-6ff558745530"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'no'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "train_data[0][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBg5Dgtx72Kx"
      },
      "source": [
        "-----\n",
        "\n",
        "## Setting up Vocabulary of All Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "collapsed": true,
        "id": "tk1x0sCp72Kx"
      },
      "outputs": [],
      "source": [
        "# Create a set that holds the vocab words\n",
        "vocab = set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "collapsed": true,
        "id": "K038m83Q72Kx"
      },
      "outputs": [],
      "source": [
        "all_data = test_data + train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "collapsed": true,
        "id": "O-Vy5DQE72Kx"
      },
      "outputs": [],
      "source": [
        "for story, question , answer in all_data:\n",
        "    # In case you don't know what a union of sets is:\n",
        "    # https://www.programiz.com/python-programming/methods/set/union\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "collapsed": true,
        "id": "iMk5L6Xo72Ky"
      },
      "outputs": [],
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMVVG8g372Ky",
        "outputId": "fb625c5f-aa39-4569-d39d-a7cf93b45c7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "collapsed": true,
        "id": "ri_xhfUB72Ky"
      },
      "outputs": [],
      "source": [
        "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "id": "VNG9mas572Ky"
      },
      "outputs": [],
      "source": [
        "max_story_len = max([len(data[0]) for data in all_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCs1dv5672Kz",
        "outputId": "8b7e1fb7-a67f-4503-fabe-4520b6b770aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "max_story_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "collapsed": true,
        "id": "aHG4l88p72Kz"
      },
      "outputs": [],
      "source": [
        "max_question_len = max([len(data[1]) for data in all_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG1jqYAa72Kz",
        "outputId": "f8e6fc06-5b3c-49f5-8c57-0a4738728199"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "max_question_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcNfiCbH72Kz"
      },
      "source": [
        "## Vectorizing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-3ZF5vS72K0",
        "outputId": "17fd7577-df9f-4550-a605-c2254b9b6ab2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "collapsed": true,
        "id": "kXaaBcAO72K0"
      },
      "outputs": [],
      "source": [
        "# Reserve 0 for pad_sequences\n",
        "vocab_size = len(vocab) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR6EmmkY72K0"
      },
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "0z6BCLoV72K0"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "collapsed": true,
        "id": "AJmZw1pG72K0"
      },
      "outputs": [],
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFwmIJ5c72K1",
        "outputId": "06212092-7d15-4096-9992-7c76ca012ec6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'in': 1,\n",
              " 'kitchen': 2,\n",
              " 'no': 3,\n",
              " 'the': 4,\n",
              " 'john': 5,\n",
              " 'down': 6,\n",
              " 'put': 7,\n",
              " 'travelled': 8,\n",
              " 'got': 9,\n",
              " 'went': 10,\n",
              " 'took': 11,\n",
              " 'to': 12,\n",
              " 'grabbed': 13,\n",
              " 'is': 14,\n",
              " 'apple': 15,\n",
              " 'office': 16,\n",
              " 'mary': 17,\n",
              " 'there': 18,\n",
              " 'up': 19,\n",
              " 'bedroom': 20,\n",
              " 'football': 21,\n",
              " 'left': 22,\n",
              " 'sandra': 23,\n",
              " 'bathroom': 24,\n",
              " 'dropped': 25,\n",
              " 'moved': 26,\n",
              " 'milk': 27,\n",
              " 'journeyed': 28,\n",
              " 'yes': 29,\n",
              " 'daniel': 30,\n",
              " 'back': 31,\n",
              " 'garden': 32,\n",
              " '?': 33,\n",
              " 'hallway': 34,\n",
              " 'picked': 35,\n",
              " '.': 36,\n",
              " 'discarded': 37}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "collapsed": true,
        "id": "-ihitdbw72K1"
      },
      "outputs": [],
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "collapsed": true,
        "id": "T0tGWUqF72K1"
      },
      "outputs": [],
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHvvGWZ372K1",
        "outputId": "e349d752-4094-4d54-b8d5-75a457cca9e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "len(train_story_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqUsWqJZ72K1",
        "outputId": "3d8c0fc6-ab40-4707-8f57-800805138eb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "len(train_story_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "collapsed": true,
        "id": "gSt83V8172K1"
      },
      "outputs": [],
      "source": [
        "# word_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9Pig9Gw72K7"
      },
      "source": [
        "### Functionalize Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "collapsed": true,
        "id": "XevvvZG972K7"
      },
      "outputs": [],
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "\n",
        "\n",
        "\n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "\n",
        "\n",
        "    for story, query, answer in data:\n",
        "\n",
        "\n",
        "        x = [word_index[word.lower()] for word in story if word.lower() in word_index] # Handle words not in vocabulary\n",
        "        xq = [word_index[word.lower()] for word in query if word.lower() in word_index] # Handle words not in vocabulary\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "\n",
        "        if answer in word_index: # Handle answers not in vocabulary\n",
        "            y[word_index[answer]] = 1\n",
        "\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "\n",
        "\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "collapsed": true,
        "id": "x9colACC72K7"
      },
      "outputs": [],
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "collapsed": true,
        "id": "G8mVZ3yx72K7"
      },
      "outputs": [],
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbmCBW7l72K7",
        "outputId": "ef72b304-aa37-4f40-f33d-20ef46a61b7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  4, 20, 36],\n",
              "       [ 0,  0,  0, ...,  4, 32, 36],\n",
              "       [ 0,  0,  0, ...,  4, 32, 36],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  4, 15, 36],\n",
              "       [ 0,  0,  0, ...,  4, 32, 36],\n",
              "       [ 0,  0,  0, ..., 15, 18, 36]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "inputs_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVkr7kGH72K8",
        "outputId": "f7b85517-749a-4f13-e3db-582fc87683a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14,  5,  1,  4,  2, 33],\n",
              "       [14,  5,  1,  4,  2, 33],\n",
              "       [14,  5,  1,  4, 32, 33],\n",
              "       ...,\n",
              "       [14, 17,  1,  4, 20, 33],\n",
              "       [14, 23,  1,  4, 32, 33],\n",
              "       [14, 17,  1,  4, 32, 33]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "queries_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbp101Zb72K8",
        "outputId": "ceef0f47-0b9f-4718-a9e7-2daf627cb287"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "answers_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvXYx32872K8",
        "outputId": "55504293-ac19-44a2-e3e6-d5c3a278a240"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "sum(answers_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyThp3Y372K8",
        "outputId": "a07ec505-03d6-4a27-d2a6-8f2b6aae2789"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "tokenizer.word_index['yes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zipp7UJJ72K9",
        "outputId": "1e7fb224-f43b-4ef5-d09f-3bd3a8087cee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "tokenizer.word_index['no']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "from keras.layers import Embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKQhDcfKHk-7",
        "outputId": "86a26eed-81c3-4227-c21e-a4b0fdc2352f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7R06si-72K9"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "collapsed": true,
        "id": "So3UdnHP72K9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Input, Activation, Dense, Dropout, Add, dot, concatenate\n",
        "from tensorflow.keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlGHZG-N72K9"
      },
      "source": [
        "### Placeholders for Inputs\n",
        "\n",
        "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "collapsed": true,
        "id": "4LiSOyhw72K9"
      },
      "outputs": [],
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "vdYqbdHH72K9"
      },
      "source": [
        "### Building the Networks\n",
        "\n",
        "To understand why we chose this setup, make sure to read the paper we are using:\n",
        "\n",
        "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
        "  \"End-To-End Memory Networks\",\n",
        "  http://arxiv.org/abs/1503.08895"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqTjosrU72K-"
      },
      "source": [
        "## Encoders\n",
        "\n",
        "### Input Encoder m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "collapsed": true,
        "id": "KfFmtnSm72K-"
      },
      "outputs": [],
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMpZ-zxL72K-"
      },
      "source": [
        "### Input Encoder c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "collapsed": true,
        "id": "sJNqFwgT72K-"
      },
      "outputs": [],
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcYJMlik72K-"
      },
      "source": [
        "### Question Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "collapsed": true,
        "id": "woVXOelt72K-"
      },
      "outputs": [],
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAJa0u3a72K_"
      },
      "source": [
        "### Encode the Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "collapsed": true,
        "id": "mkDWwp6N72K_"
      },
      "outputs": [],
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pszz29iN72K_"
      },
      "source": [
        "##### Use dot product to compute the match between first input vector seq and the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "collapsed": true,
        "id": "CAdIjtUj72K_"
      },
      "outputs": [],
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0DiSx04PH9QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iRCj7aG72K_"
      },
      "source": [
        "#### Add this match matrix with the second input vector sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "5eUMsj0g72K_",
        "outputId": "f0e7bc90-1c84-4665-883d-16a84f137990"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "_Merge.__init__() takes 1 positional argument but 2 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-451b1c2649e0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# add the match matrix with the second input vector sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoded_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (samples, story_maxlen, query_maxlen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (samples, query_maxlen, story_maxlen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _Merge.__init__() takes 1 positional argument but 2 were given"
          ]
        }
      ],
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = Add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = Add()([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "XvC4MQcNIZ1p",
        "outputId": "67d89684-77ef-46f8-da07-bbe3e3fcfb29"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Permute' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-0eac57e7ba7a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# add the match matrix with the second input vector sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoded_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (samples, story_maxlen, query_maxlen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (samples, query_maxlen, story_maxlen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Permute' is not defined"
          ]
        }
      ]
    },
    {
      "source": [
        "from tensorflow.keras.layers import Permute, Add\n",
        "\n",
        "# add the match matrix with the second input vector sequence\n",
        "response = Add()([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "qE1kFWPOIirz"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0HyShc572K_"
      },
      "source": [
        "#### Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "collapsed": true,
        "id": "kZKj44bO72LA"
      },
      "outputs": [],
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoiE79sP72LA",
        "outputId": "6c2db0f5-446b-4f0c-a28f-2f222be1bc7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "collapsed": true,
        "id": "SkOZg9WH72LA"
      },
      "outputs": [],
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "collapsed": true,
        "id": "D7Atw2mj72LA"
      },
      "outputs": [],
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "collapsed": true,
        "id": "VSxW1I0672LA"
      },
      "outputs": [],
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srfc-NeM72LA",
        "outputId": "4a11a380-8b91-4749-b97f-eb764937acf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 156)]                0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 6)]                  0         []                            \n",
            "                                                                                                  \n",
            " sequential (Sequential)     (None, None, 64)             2432      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)   (None, 6, 64)                2432      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dot (Dot)                   (None, 156, 6)               0         ['sequential[0][0]',          \n",
            "                                                                     'sequential_2[0][0]']        \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 156, 6)               0         ['dot[0][0]']                 \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)   (None, None, 6)              228       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 156, 6)               0         ['activation[0][0]',          \n",
            "                                                                     'sequential_1[0][0]']        \n",
            "                                                                                                  \n",
            " permute (Permute)           (None, 6, 156)               0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 6, 220)               0         ['permute[0][0]',             \n",
            "                                                                     'sequential_2[0][0]']        \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 32)                   32384     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 32)                   0         ['lstm[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 38)                   1254      ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 38)                   0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38730 (151.29 KB)\n",
            "Trainable params: 38730 (151.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZfQ-OJ572LB",
        "outputId": "c8aed307-b543-4edb-c1ed-142c632a5adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "313/313 [==============================] - 9s 21ms/step - loss: 0.9479 - accuracy: 0.4905 - val_loss: 0.6951 - val_accuracy: 0.4970\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.7086 - accuracy: 0.5017 - val_loss: 0.6935 - val_accuracy: 0.5030\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6989 - accuracy: 0.4981 - val_loss: 0.6949 - val_accuracy: 0.4970\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.6964 - accuracy: 0.5032 - val_loss: 0.6946 - val_accuracy: 0.4970\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6957 - accuracy: 0.5080 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6959 - accuracy: 0.4910 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6957 - accuracy: 0.4886 - val_loss: 0.6938 - val_accuracy: 0.5030\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6957 - accuracy: 0.4956 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 0.6953 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6947 - accuracy: 0.4989 - val_loss: 0.6963 - val_accuracy: 0.4970\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6960 - accuracy: 0.4945 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6954 - accuracy: 0.4961 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6951 - accuracy: 0.4965 - val_loss: 0.6950 - val_accuracy: 0.5030\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6950 - accuracy: 0.5009 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6949 - accuracy: 0.5091 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6952 - accuracy: 0.4937 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6947 - accuracy: 0.4977 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6951 - accuracy: 0.5001 - val_loss: 0.6954 - val_accuracy: 0.4970\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6952 - accuracy: 0.4979 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6954 - accuracy: 0.4937 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6947 - accuracy: 0.5014 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6949 - accuracy: 0.5012 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6947 - accuracy: 0.5019 - val_loss: 0.6939 - val_accuracy: 0.4970\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6957 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6950 - accuracy: 0.4961 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6945 - accuracy: 0.5029 - val_loss: 0.6955 - val_accuracy: 0.4970\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6944 - accuracy: 0.5044 - val_loss: 0.6949 - val_accuracy: 0.4970\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6951 - accuracy: 0.4996 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6946 - accuracy: 0.5035 - val_loss: 0.6939 - val_accuracy: 0.5030\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6948 - accuracy: 0.5022 - val_loss: 0.6994 - val_accuracy: 0.4970\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6949 - accuracy: 0.5005 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6954 - accuracy: 0.4882 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6942 - accuracy: 0.4981 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6950 - accuracy: 0.5016 - val_loss: 0.6953 - val_accuracy: 0.4970\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6949 - accuracy: 0.4994 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6951 - accuracy: 0.4978 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6954 - accuracy: 0.4899 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6950 - accuracy: 0.4927 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6946 - accuracy: 0.4971 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6950 - accuracy: 0.5004 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6947 - accuracy: 0.4980 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6945 - accuracy: 0.5048 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6946 - accuracy: 0.5018 - val_loss: 0.6945 - val_accuracy: 0.4970\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6946 - accuracy: 0.5073 - val_loss: 0.6949 - val_accuracy: 0.4970\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6945 - accuracy: 0.5119 - val_loss: 0.6948 - val_accuracy: 0.4970\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6943 - accuracy: 0.5018 - val_loss: 0.6939 - val_accuracy: 0.5030\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6945 - accuracy: 0.5038 - val_loss: 0.6959 - val_accuracy: 0.4970\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.6945 - accuracy: 0.5052 - val_loss: 0.6941 - val_accuracy: 0.4890\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6939 - accuracy: 0.5115 - val_loss: 0.6945 - val_accuracy: 0.4970\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6936 - accuracy: 0.5129 - val_loss: 0.6938 - val_accuracy: 0.5040\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6941 - accuracy: 0.5100 - val_loss: 0.6945 - val_accuracy: 0.5110\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6921 - accuracy: 0.5208 - val_loss: 0.6952 - val_accuracy: 0.4930\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6918 - accuracy: 0.5216 - val_loss: 0.6938 - val_accuracy: 0.5040\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6903 - accuracy: 0.5259 - val_loss: 0.6940 - val_accuracy: 0.5070\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6857 - accuracy: 0.5336 - val_loss: 0.6904 - val_accuracy: 0.5160\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6777 - accuracy: 0.5530 - val_loss: 0.6801 - val_accuracy: 0.5390\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6643 - accuracy: 0.5848 - val_loss: 0.6587 - val_accuracy: 0.6320\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6536 - accuracy: 0.5971 - val_loss: 0.6516 - val_accuracy: 0.6280\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6414 - accuracy: 0.6204 - val_loss: 0.6401 - val_accuracy: 0.6390\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6394 - accuracy: 0.6233 - val_loss: 0.6239 - val_accuracy: 0.6390\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6311 - accuracy: 0.6313 - val_loss: 0.6219 - val_accuracy: 0.6410\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6298 - accuracy: 0.6325 - val_loss: 0.6135 - val_accuracy: 0.6600\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6214 - accuracy: 0.6401 - val_loss: 0.6063 - val_accuracy: 0.6700\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6152 - accuracy: 0.6593 - val_loss: 0.6067 - val_accuracy: 0.6640\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6097 - accuracy: 0.6669 - val_loss: 0.5975 - val_accuracy: 0.6740\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6048 - accuracy: 0.6723 - val_loss: 0.5876 - val_accuracy: 0.6970\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.5930 - accuracy: 0.6848 - val_loss: 0.5890 - val_accuracy: 0.6900\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.5833 - accuracy: 0.6926 - val_loss: 0.5807 - val_accuracy: 0.7060\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.5776 - accuracy: 0.7033 - val_loss: 0.5677 - val_accuracy: 0.7140\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.5634 - accuracy: 0.7171 - val_loss: 0.5596 - val_accuracy: 0.7170\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.5582 - accuracy: 0.7213 - val_loss: 0.5419 - val_accuracy: 0.7270\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.5441 - accuracy: 0.7329 - val_loss: 0.5299 - val_accuracy: 0.7350\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.5292 - accuracy: 0.7468 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 0.5193 - accuracy: 0.7541 - val_loss: 0.5019 - val_accuracy: 0.7540\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.4952 - accuracy: 0.7671 - val_loss: 0.4839 - val_accuracy: 0.7720\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.4761 - accuracy: 0.7845 - val_loss: 0.4760 - val_accuracy: 0.7780\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4523 - accuracy: 0.7972 - val_loss: 0.4317 - val_accuracy: 0.8040\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.4424 - accuracy: 0.8073 - val_loss: 0.4143 - val_accuracy: 0.8170\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.4207 - accuracy: 0.8174 - val_loss: 0.4172 - val_accuracy: 0.8050\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.4141 - accuracy: 0.8187 - val_loss: 0.4131 - val_accuracy: 0.8050\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3992 - accuracy: 0.8305 - val_loss: 0.4103 - val_accuracy: 0.8130\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3992 - accuracy: 0.8284 - val_loss: 0.3943 - val_accuracy: 0.8230\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3835 - accuracy: 0.8366 - val_loss: 0.4317 - val_accuracy: 0.8000\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3805 - accuracy: 0.8315 - val_loss: 0.4084 - val_accuracy: 0.8040\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3760 - accuracy: 0.8381 - val_loss: 0.3974 - val_accuracy: 0.8180\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3738 - accuracy: 0.8386 - val_loss: 0.3870 - val_accuracy: 0.8160\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3615 - accuracy: 0.8464 - val_loss: 0.3943 - val_accuracy: 0.8150\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3602 - accuracy: 0.8459 - val_loss: 0.4049 - val_accuracy: 0.8160\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3524 - accuracy: 0.8487 - val_loss: 0.4005 - val_accuracy: 0.8260\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3534 - accuracy: 0.8482 - val_loss: 0.3862 - val_accuracy: 0.8160\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3494 - accuracy: 0.8495 - val_loss: 0.3731 - val_accuracy: 0.8250\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3407 - accuracy: 0.8515 - val_loss: 0.3984 - val_accuracy: 0.8180\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3431 - accuracy: 0.8503 - val_loss: 0.3908 - val_accuracy: 0.8260\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3393 - accuracy: 0.8498 - val_loss: 0.3879 - val_accuracy: 0.8180\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3424 - accuracy: 0.8499 - val_loss: 0.3883 - val_accuracy: 0.8180\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3360 - accuracy: 0.8534 - val_loss: 0.3798 - val_accuracy: 0.8190\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3371 - accuracy: 0.8544 - val_loss: 0.3863 - val_accuracy: 0.8160\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3331 - accuracy: 0.8552 - val_loss: 0.3794 - val_accuracy: 0.8200\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3269 - accuracy: 0.8567 - val_loss: 0.3884 - val_accuracy: 0.8220\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3277 - accuracy: 0.8587 - val_loss: 0.4613 - val_accuracy: 0.8190\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3258 - accuracy: 0.8586 - val_loss: 0.3992 - val_accuracy: 0.8190\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3287 - accuracy: 0.8590 - val_loss: 0.3919 - val_accuracy: 0.8180\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3251 - accuracy: 0.8553 - val_loss: 0.3877 - val_accuracy: 0.8270\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3176 - accuracy: 0.8581 - val_loss: 0.3975 - val_accuracy: 0.8190\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3221 - accuracy: 0.8612 - val_loss: 0.4119 - val_accuracy: 0.8180\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3243 - accuracy: 0.8603 - val_loss: 0.3946 - val_accuracy: 0.8140\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3195 - accuracy: 0.8630 - val_loss: 0.4002 - val_accuracy: 0.8170\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3210 - accuracy: 0.8612 - val_loss: 0.3856 - val_accuracy: 0.8250\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 0.3127 - accuracy: 0.8637 - val_loss: 0.4515 - val_accuracy: 0.8160\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3091 - accuracy: 0.8649 - val_loss: 0.3987 - val_accuracy: 0.8300\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3145 - accuracy: 0.8610 - val_loss: 0.3926 - val_accuracy: 0.8250\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3136 - accuracy: 0.8629 - val_loss: 0.3971 - val_accuracy: 0.8150\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3074 - accuracy: 0.8667 - val_loss: 0.4001 - val_accuracy: 0.8170\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3038 - accuracy: 0.8660 - val_loss: 0.4139 - val_accuracy: 0.8210\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3083 - accuracy: 0.8704 - val_loss: 0.3995 - val_accuracy: 0.8190\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.2991 - accuracy: 0.8719 - val_loss: 0.4239 - val_accuracy: 0.8270\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3037 - accuracy: 0.8694 - val_loss: 0.4211 - val_accuracy: 0.8210\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3017 - accuracy: 0.8709 - val_loss: 0.4136 - val_accuracy: 0.8220\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3024 - accuracy: 0.8671 - val_loss: 0.4168 - val_accuracy: 0.8200\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2979 - accuracy: 0.8723 - val_loss: 0.3997 - val_accuracy: 0.8260\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4yjUMgm72LB"
      },
      "source": [
        "### Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "collapsed": true,
        "id": "8rXIOX-v72LB"
      },
      "outputs": [],
      "source": [
        "filename = 'chatbot_120_epochs.h6'\n",
        "model.save(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-rbQGDp72LB"
      },
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "### Plotting Out Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjzWD9rg72LB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkbUkrD872LB"
      },
      "source": [
        "### Evaluating on Given Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wtf2nRos72LB"
      },
      "outputs": [],
      "source": [
        "model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z3ecoMx72LC"
      },
      "outputs": [],
      "source": [
        "test_data[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bzNdDD-72LC",
        "outputId": "635587ba-38ee-48ee-93e9-ecb04863d8e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mary got the milk there . John moved to the bedroom .\n"
          ]
        }
      ],
      "source": [
        "story =' '.join(word for word in test_data[0][0])\n",
        "print(story)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpgOr3Ef72LC",
        "outputId": "c37f45ca-ea75-4e6d-e2c5-015ecf0d25a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is John in the kitchen ?\n"
          ]
        }
      ],
      "source": [
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4eVPNRe72LC",
        "outputId": "ee0d4f84-f77e-45dc-c072-ea9779941da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Test Answer from Data is: no\n"
          ]
        }
      ],
      "source": [
        "print(\"True Test Answer from Data is:\",test_data[0][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pX_YjLg72LC",
        "outputId": "042e733d-42a1-4e44-dec9-27afe824022b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.9999999\n"
          ]
        }
      ],
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI4BUzP372LC"
      },
      "source": [
        "## Writing Your Own Stories and Questions\n",
        "\n",
        "Remember you can only use words from the existing vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njT-4zQR72LD",
        "outputId": "1f9efff8-e9b3-4514-9c64-16c500b28969"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5WESwPC72LD",
        "outputId": "683c3078-6533-4da3-cc68-8246081457f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note the whitespace of the periods\n",
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G8zZHf4c72LD"
      },
      "outputs": [],
      "source": [
        "my_question = \"Is the football in the garden ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kFrmofM72LD",
        "outputId": "c67b9b09-876e-483d-aaa1-c7a4d9477164"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_question.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yJVyeAwP72LD"
      },
      "outputs": [],
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NGyAKTGp72LD"
      },
      "outputs": [],
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IqsPGm-872LD"
      },
      "outputs": [],
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p9CQYR772LE",
        "outputId": "60599880-8e7b-4bf7-8263-187ca2ef350d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.97079676\n"
          ]
        }
      ],
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}